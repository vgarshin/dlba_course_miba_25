{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 15: Texts classification with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maQhPv_GLGGJ"
   },
   "source": [
    "Submission:\n",
    "* There is no late submission for this assignment.\n",
    "* It is individual work.\n",
    "* Each student should submit an .ipynb file to the Teams Assignment.\n",
    "* Grading: 0-15% of the course.\n",
    "\n",
    "### <font color='red'>HOME ASSIGNMENT</font>\n",
    "Here is a <a href=\"https://huggingface.co/datasets/banking77\">dataset</a> composed of online banking queries annotated with their corresponding intents. You can download it by running the cell below. The data will be saved in the working directory.\n",
    "\n",
    "DO NOT USE function ```datasets.load('banking77')```! Run the cell below and work with raw data.\n",
    "\n",
    "What I expect you to do:\n",
    "* Explore data: shape, number of classes, balance of classes. __2 points__.\n",
    "* Solve a classification problem for a dataset using any <a href=\"https://huggingface.co/docs/transformers/tasks/sequence_classification\">transformer</a> from the huggingface library. __3 points__.  \n",
    "The tutorial at the link might be helpful.\n",
    "* Justify choice of a metric. __3 points__.\n",
    "* Split the training dataset into train and valid datasets. Train the model on train dataset and evaluate it on the valid dataset during training. Evaluate model on the test dataset after training. DO NOT USE a test dataset for validation!  __2 points__.\n",
    "* Come up with 3 or more queries on banking topics and make a forecast of intents using your model. __2 points__.\n",
    "* Comment code and describe your actions in the notebook. __1 point__.\n",
    "* You must achieve a metric value of at least 90% __2 points__.\n",
    "* Attach this file to the Teams Assignment. If you do not attach the file, you will get __0 points__.\n",
    "\n",
    "The final score is calculated as a sum of all points.\n",
    "\n",
    "If any of the tasks below will be completed with an error, the number of points for it may be reduced. For example, if you wrote only one query to the model instead of at least 3, then instead of __2 points__ you will get __1 point__.\n",
    "\n",
    "### Notes\n",
    "* Feel free to ask questions.\n",
    "* Google Colab and Kaggle provide some free CPU and GPU time. Feel free to use it or use university resources.\n",
    "* Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASPHERE = False\n",
    "\n",
    "if DATASPHERE:\n",
    "    # !!! ATTENTION for DataSphere !!!\n",
    "    # You will need to restart kernel\n",
    "    # after libraries installed\n",
    "    %pip install transformers==4.49.0 evaluate accelerate\n",
    "else:\n",
    "    !pip install tensorflow-cpu==2.16.1\n",
    "    !pip install tf-keras==2.16.0 --no-dependencies\n",
    "    !pip install transformers evaluate accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgOSXEFZSzUB"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -q -nc \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv\"\n",
    "wget -q -nc \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX44YTFYZALu"
   },
   "source": [
    "### 3. Solutions\n",
    "#### Task #1: Start with the data\n",
    "* Read train and test data.\n",
    "* Explore data: shape, number of classes, balance of classes. Bar chart from `plotly.express` can be helpful.\n",
    "* Is there a class imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKrKLm1OSOE3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-RNQ-PkSP8l"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUfP8KgxSX7s"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQstaO3-bI_B"
   },
   "source": [
    "#### Task #2: Prepare datasets to train a model.\n",
    "* Create `label2id` and `id2label` mappings.\n",
    "* Create a `label` column in train and test datasets.\n",
    "* Split train dataset to train and valid. Select proportion. Don't forget to fix the `seed`. Use stratification if you need.\n",
    "* For model training, it will be useful to wrap your dataframes in `Dataset` and `DatasetDict` objects of the `datasets` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-uLVnosaox9"
   },
   "outputs": [],
   "source": [
    "id2label = {i:c for i, c in enumerate(set(train['category']))}\n",
    "label2id = {c:i for i, c in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_Y7N-jmbH-w"
   },
   "outputs": [],
   "source": [
    "for i, c in id2label.items():\n",
    "    assert label2id[c] == i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMLmXgcsuXol"
   },
   "outputs": [],
   "source": [
    "train['label'] = train['category'].map(label2id)\n",
    "test['label'] = test['category'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjLqKhFZVTXj"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kENttOpDii7s"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_U9IQtuimw0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9rLYXS_thQ0"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MgcxslctiI2"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_z784TjfW25"
   },
   "source": [
    "#### Task #3: Fit the model\n",
    "* Choose a model, for example, `roberta-base`.\n",
    "* Download the appropriate tokenizer and apply it to the dataset. Do not forget to truncate long sequences.\n",
    "* Create ever `DataCollatorWithPadding` and metric.\n",
    "* Create e`DataCollatorWithPadding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcsb3hwOVuoT"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhJ_E2hkx4Mi"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(lambda data: tokenizer(data['text'], truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cV_f5eKqXowq"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhN4nNFsY_X0"
   },
   "outputs": [],
   "source": [
    "f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyzdzgmdZPpS"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    f1_macro = f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    f1_weighted = f1.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    metrics = dict(f1_macro=f1_macro['f1'], f1_weighted=f1_weighted['f1'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4GIeBabbYQb"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgvbNDRHbkUv"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzLB8p-pI1v0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXd2IDCkfHW/543W4IF2FL",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
