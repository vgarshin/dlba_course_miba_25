{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 11: Classical methods of machine learning in natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understanding the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o35wFeQyYAY"
   },
   "source": [
    "Today we are going to build a simple text classifier.  \n",
    "Suppose we own a big online shop and our customers are able to write a feedback and rate products after the purchase from 1 to 5:\n",
    "\n",
    "1. awfull\n",
    "2. not very nice\n",
    "3. normal\n",
    "4. nice\n",
    "5. awesome\n",
    "\n",
    "Some of our customers wrote a feedback but decided not to rate a product. Suppose one of the shop KPIs is a percentage of a nice and awesome products that we sold to our customers. We can simply calculate this KPI using avaliable rates. Let's define:\n",
    "\n",
    "$$good=\\#4 + \\#5$$\n",
    "$$bad=\\#1 + \\#2 + \\#3$$\n",
    "\n",
    "where $\\#A$ means \"count of $A$ rate\", $A=\\overline{1,5}$.  \n",
    "Then KPI will be:\n",
    "\n",
    "$$KPI = \\frac{good}{good + bad}$$\n",
    "\n",
    "We read sample of rate comments and figured out that sentiment of the feedback correlated with rate, in other words if customer satisfied with the product the rate is hight and vice versa.\n",
    "\n",
    "Knowing that, can we somehow improve estimation of the KPI using feedback of the unrated products? Yes, of course. We can build a binary classifier which takes feedback as an input and predicts probability of a good product:\n",
    "$$p=p(x, θ)=P(y = 1|x, θ),$$\n",
    "were $x$ is a feedback, $θ$ is a model weights, and $y$ is binary variable that takes two values: $1$ —  product is good and $0$ — product is bad.  \n",
    "\n",
    "Probability of a bad product will be:\n",
    "$$P(y = 0|x, θ) = 1 - P(y = 1|x, θ) = 1 - p(x, θ) = 1 - p$$\n",
    "\n",
    "If we know $p$ how to go from it to classes? We should choose probability threshold $t$:\n",
    "* If $p >= t$ then $y=1$ witch means it's a good product.\n",
    "* If $p < t$ then $y=0$ witch means it's a bad product.\n",
    "\n",
    "We are going to use binary cross entropy loss for training as usual:\n",
    "\n",
    "$$L(x, θ) = -\\sum_{i=1}^{m}{y_i log(p_i) + (1-y_i)log(1-p_i)}$$\n",
    "\n",
    "where $m$ is a count of texts in the training set, $y_i$ is a target label of text $i$ and $p_i$ is a probability of text $i$ is good predicted by a classifier.\n",
    "\n",
    "Gradient descent is already implemented in sklearn.\n",
    "\n",
    "In this work we will be using data from this resource: http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcOnnnUtNz9r"
   },
   "source": [
    "### 2. Data exploration\n",
    "\n",
    "First of all, let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZtI9Mw7zNFp"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "REVIEW_NAME=\"reviews_Clothing_Shoes_and_Jewelry_5.json\"\n",
    "wget -q -nc \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/$REVIEW_NAME.gz\"\n",
    "if [ ! -f $REVIEW_NAME ]; then\n",
    "    gzip -dk $REVIEW_NAME;\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3FzZZGuB6BD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 13297,
     "status": "ok",
     "timestamp": 1729514831916,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "sV1vWM8QCBAG",
    "outputId": "6df9c111-a5c5-4090-f15a-d8c454f1f8ef"
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/jovyan/__DATA/DLBA_F25/topic_11\"\n",
    "reviews = pd.read_json(\n",
    "    f\"{data_path}/reviews_Clothing_Shoes_and_Jewelry_5.json\", \n",
    "    lines=True\n",
    ")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Qhk-t1ahuI6"
   },
   "source": [
    "Our data contains three usefull columns:\n",
    "\n",
    "* `reviewText` − customer feedback\n",
    "* `summary` − short summary of customer feedback\n",
    "* `overall` − rate of product\n",
    "\n",
    "We could build two classifiers with `summary` and `reviewText` as input text respectively, but to simplify our life we can concatenate them as if `summary` is a first sentense of customer feedback.\n",
    "\n",
    "In the next cell write a code which concatenates strings in columns `summary` and `reviewText` separated by space and assign the result to a new column `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1729514832790,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "u5Lpzq5qb96J",
    "outputId": "4113a08c-29b7-4b36-d241-824709b89c09"
   },
   "outputs": [],
   "source": [
    "reviews['text'] = reviews['summary'] + ' ' + reviews['reviewText']\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGa8i3KBksyZ"
   },
   "source": [
    "Let's look at the distribution of rates.  \n",
    "Create a new dataframe `rating_dist` with two columns:\n",
    "* `overall` - unique rates from 1 to 5\n",
    "* `count` - count of rates in our `reviews` dataframe\n",
    "\n",
    "Describe the resulting pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 5595,
     "status": "ok",
     "timestamp": 1729514838383,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "nrGp8ExrNe5y",
    "outputId": "1d54523a-4951-45f1-e5b0-ee883fca5150"
   },
   "outputs": [],
   "source": [
    "rating_dist = reviews \\\n",
    "    .groupby('overall')[['overall']] \\\n",
    "    .count() \\\n",
    "    .rename(columns={'overall': 'count'}) \\\n",
    "    .reset_index()\n",
    "\n",
    "px.pie(\n",
    "    rating_dist, \n",
    "    names='overall', \n",
    "    values='count', \n",
    "    title='Ratings distribution', \n",
    "    width=640, height=480, \n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgwJsGWUnPfJ"
   },
   "source": [
    "### 3. Analysis of the target variable\n",
    "\n",
    "It's time to calculate our target variable.  \n",
    "Recall that $y=1$ means the product is good and $y=0$ means the product is bad. Good products have rates 4, 5 and bad products have rates 1, 2, 3.\n",
    "\n",
    "Add a new column `target` to `reviews` dataframe following the above logic.\n",
    "\n",
    "Then create a new dataframe `rating_dist` again with two columns:\n",
    "* `target` - unique values 0 and 1\n",
    "* `count` - count of rates in our `reviews` dataframe\n",
    "\n",
    "Look at the pie chart. What can you say about class balance? Can it cause the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729514838383,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "VJ1r3AI2KL1U",
    "outputId": "8855f944-1ffe-4d6c-93ec-efa45d806b9a"
   },
   "outputs": [],
   "source": [
    "reviews['target'] = np.where(reviews['overall'] < 4, 0, 1)\n",
    "\n",
    "rating_dist = reviews \\\n",
    "    .groupby('target')[['target']] \\\n",
    "    .count() \\\n",
    "    .rename(columns={'target': 'count'}) \\\n",
    "    .reset_index()\n",
    "\n",
    "px.pie(\n",
    "    rating_dist, \n",
    "    names='target', \n",
    "    values='count', \n",
    "    title='Target distribution', \n",
    "    width=640, height=480, \n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiEfpGVStzpO"
   },
   "source": [
    "### 4. Deal with balance\n",
    "\n",
    "There are different approaches to deal with imbalanced classes: adding the weights of classes in our loss function, make upsampling, make downsampling, generate synthetic data of minority class etc.\n",
    "\n",
    "In this work we will use downsampling. It is a very simple technique. We have 20.5% reviews from class \"0\" and 79.5% examples from class \"1\". We will remove some objects from class \"1\" so that the class balance is 50/50.\n",
    "\n",
    "Find out how many objects in class \"0\" we have and sample the same amount of objects from class \"1\". Set parameter `random_state=0` to make sampling reproducible. Then combine objects from class \"0\" and resulting sample to one dataset `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729514838383,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "GgzaNDCt2yuc",
    "outputId": "870af4af-e462-490b-b3d3-6facdd7a5cb6"
   },
   "outputs": [],
   "source": [
    "rating_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1729514839166,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "litvBxXDYq97",
    "outputId": "a17f0f4d-84e0-4ecf-fedb-58797228c906",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_counts = rating_dist[rating_dist['target'] == 0]['count'][0]\n",
    "\n",
    "good_reviews = reviews[reviews['target'] == 1].sample(bad_counts, random_state=0)\n",
    "bad_reviews = reviews[reviews['target'] == 0]\n",
    "\n",
    "data = pd.concat([good_reviews, bad_reviews], ignore_index=True)\n",
    "\n",
    "print('Data shape:', data.shape)\n",
    "display(data.head(5), data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tokenization approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-agN8YpNv9N"
   },
   "source": [
    "#### 5.1. Bag of words model\n",
    "\n",
    "To build a binary clissifier we need binary target variable that we already calculated and input features. So, somehow we need to extract features from the text of feedback. Let's create a vector representations of each text. The simplest way to do it is a bag-of-words model (BOW). The BOW assumes that text can be represented of its words and disregarding word order. Word is a feature in this model and frequency of particular word in the text is the value of the featur. It means that to make a vector representations we need to create a vocabulary of all words in the corpus and count of each word in each text.\n",
    "\n",
    "For example, if we have a corpus of two lowercase texts:\n",
    "* \"this product is awesome. product has awesome functions.\"\n",
    "* \"this product is disgusting. it does not work\"\n",
    "\n",
    "then vector representation will look like this:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>this</th> <th>product</th> <th>is</th> <th>awesome</th> <th>.</th>\n",
    "    <th>has</th> <th>functions</th> <th>disgusting</th> <th>it</th>\n",
    "    <th>does</th> <th>not</th> <th>work</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td> <td>2</td> <td>1</td> <td>2</td> <td>2</td> <td>1</td> <td>1</td>\n",
    "    <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td> <td>1</td> <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td>\n",
    "    <td>1</td> <td>1</td> <td>1</td> <td>1</td> <td>1</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Instead of count we can calculate the term frequency (TF):\n",
    "\n",
    "$$TF(text, word) = \\frac{n_k}{\\sum_{k} n_k}$$\n",
    "\n",
    "where $n_k$ is count of partiqular word in the document and $\\sum_{k} n_k$ is the count of all words in document.\n",
    "\n",
    "You can consider this transformation as a type of scaling. Input vectors will be look like this:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>this</th> <th>product</th> <th>is</th> <th>awesome</th> <th>.</th>\n",
    "    <th>has</th> <th>functions</th> <th>disgusting</th> <th>it</th>\n",
    "    <th>does</th> <th>not</th> <th>work</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.1</td> <td>0.2</td> <td>0.1</td> <td>0.2</td> <td>0.2</td>\n",
    "    <td>0.1</td> <td>0.1</td> <td>0.0</td> <td>0.0</td> <td>0.0</td>\n",
    "    <td>0.0</td> <td>0.0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.11</td> <td>0.11</td> <td>0.11</td> <td>0.0</td> <td>0.11</td>\n",
    "    <td>0.0</td> <td>0.0</td> <td>0.11</td> <td>0.11</td> <td>0.11</td>\n",
    "    <td>0.11</td> <td>0.11</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Another improvement we can make is to reduce the weights of commonly used words.\n",
    "Let's calculate weight of each word like this:\n",
    "\n",
    "$$IDF(word) = log(\\frac{N}{df_w})$$\n",
    "\n",
    "where $N$ is a count of documents(texts) in the corpus and $df_w$ is a count of documents containing word $w$.\n",
    "\n",
    "If some word occurs in all documents then $IDF = log(\\frac{N}{N}) = 0$.\n",
    "\n",
    "The final feature is called TF-IDF and calculated like this:\n",
    "\n",
    "$$TF\\text{-}IDF = TF * IDF$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0bJ1jWgu_l3"
   },
   "source": [
    "#### 5.2. N-gram model\n",
    "\n",
    "Disregarding word order can cause a problem. Suppose we have texts:\n",
    "* \"This product is nice.\"\n",
    "* \"This product is not nice.\"\n",
    "\n",
    "Vectors of this two texts will be very close in BOW feature space and model can predict that both products is good. To avoid this problem we can use pair of words 'not nice' as a feature insted of just separate words 'not' and 'nice'. Pair of two words in text called a bigram. For example, we can write all bigrams of second sentence:  \n",
    "\n",
    "`['This product', 'product is', 'is not', 'not nice']`  \n",
    "\n",
    "The common model is called n-gram, that contains sequences of n words as a features. For example, `nice` is unigram(word), `product is not` is a 3-gram, `This product is not` is a 4-gram.\n",
    "\n",
    "We can union unigrams, bigrams, threegrams etc. to create a dataset for a better model. Frequencies of n-grams is calculated the same way as frequency of words.\n",
    "\n",
    "But be careful and don't add a lot of different n-grams. It can cause overfitting. Here we can draw an analogy with adding polynomial features in a model when we work with tabular data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5h5HYn_ymg3"
   },
   "source": [
    "### 6. Texts Preprocessing\n",
    "\n",
    "Now let's prepare our corupus to modeling.\n",
    "\n",
    "The first thing that we should do is to clean each text from trash. It can be special unicode symbols, characters like @#$% inside words, etc. An approach of cleaning is always different for each task. In our case we will be following the hypotesis that rates depend on words in feedback and no punctuation symbols have influence on rates. So we will remove everything except letters.\n",
    "\n",
    "The second step is tokenization. We should split each text into words.\n",
    "\n",
    "After tokenization we may figure out that our courpus contains a lot of the same words but in different forms. For example:\n",
    "`['walk', 'walking', 'walked']` or `['go', 'went', 'gone']`.\n",
    "It will increase volume of our feature space because all of this words is a feature. To reduce dimension we can use stemming or lemmatization.\n",
    "\n",
    "Stemming is the process of reducing inflected words to their word base. For example, `walk` is the base of word `walking`. Stemmer will remove prefixes or suffixex of word, in this case `-ing` suffix.\n",
    "\n",
    "Lemmatization is the process of converting an inflected word to its normal form.\n",
    "For example, `go` is a normal form of `went`.\n",
    "\n",
    "Last step is a removing a stop words. Stop word is a very common words in language like prepositions, particles, articles etc.\n",
    "\n",
    "It is not a full list of preprocessing steps but it will be sufficient for this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12477,
     "status": "ok",
     "timestamp": 1729514851640,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "qr8wRM1QUB_5",
    "outputId": "e7eaa5b2-0f92-4f14-a074-4606acf08fcd"
   },
   "outputs": [],
   "source": [
    "# Download some necessary packages for nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMbSscyBB457"
   },
   "outputs": [],
   "source": [
    "# import packages for preprocessing text\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from functools import lru_cache\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdXhTK6eiiHD"
   },
   "outputs": [],
   "source": [
    "# for beautiful progress bar\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Y4XNUbgeOL1"
   },
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words('english'))  # get a set of stopwords\n",
    "cleaner = re.compile('[^A-Za-z \\']')  # regular expression for cleaning text\n",
    "stemmer = SnowballStemmer('english')  # for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIPX0PdpgDTb"
   },
   "outputs": [],
   "source": [
    "# Use this function to stem a word(token). It works much faster because\n",
    "# it saves each word and result in cache and doesn't do stemming if the\n",
    "# word has been seen already.\n",
    "@lru_cache(maxsize=None)\n",
    "def stem(token):\n",
    "    return stemmer.stem(token)\n",
    "\n",
    "# Implement following steps:\n",
    "# - replace all trash symbols to spaces.\n",
    "# - convert the string to lowercase.\n",
    "# - tokenize a string using function word_tokenize(...).\n",
    "# - stem each token and if it's not a stop word add token to list `lem_tokens`\n",
    "def preprocess(text):\n",
    "    string = cleaner.sub(' ', text)\n",
    "    tokens = word_tokenize(string.lower(), language='english')\n",
    "    lem_tokens = []\n",
    "    for token in tokens:\n",
    "        l_token = stem(token)\n",
    "        if l_token not in stopwords_set:\n",
    "            lem_tokens.append(l_token)\n",
    "    return ' '.join(lem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "8ffde06366dd438d9d9e725942e6e2bc",
      "15f4d6b7130546feb1807f8452d4b8d4",
      "37f74dd0fc014c12b8837f0f0ae97bd6",
      "5e77764fedd54b9e8bb391b862491084",
      "5e6ed618235e43beb304b2a9821f75ff",
      "30890c0f05d44a0699207d43e95c15b8",
      "447ace2b92cd4246a2ba84492f9ccb11",
      "dd8eb4c615554303a51e87c33ea04617",
      "8e0d4d585bef42c2bd531d33c599d3f0",
      "2b9f86fa5775429695296e4b4d686abc",
      "5f42323de1414ca585f48db27cbdf47a"
     ]
    },
    "executionInfo": {
     "elapsed": 76722,
     "status": "ok",
     "timestamp": 1729514928773,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "EGgrYuf9isSq",
    "outputId": "770ebabf-c624-4822-c95b-a2c32de19587"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# run preprocess for each text\n",
    "data['bow'] = data['text'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729514928773,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "0bmy2tPf7QtW",
    "outputId": "4f810fa0-0218-4906-d2a7-4113fb563240"
   },
   "outputs": [],
   "source": [
    "data[\"bow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoNJcj_GrUD3"
   },
   "outputs": [],
   "source": [
    "# create input and target\n",
    "X = data['bow']\n",
    "y = data['target']\n",
    "\n",
    "# split dataset to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1729514929055,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "qBPNY3wl7lwo",
    "outputId": "de601d8b-6e37-4ee6-f884-5e3550bb5425"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss1vMPh2zNs6"
   },
   "outputs": [],
   "source": [
    "# import class TfidfVectorizer that transform our texts to vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11690,
     "status": "ok",
     "timestamp": 1729514940743,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "Y-MgIh1BrMC8",
    "outputId": "b7d2d8c1-3ad7-46e3-a154-d2ecc34c0f83"
   },
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object with unigrams and bigrams and use parameters\n",
    "# min_df to ignore n-grams that appear in fewer than 15 documents\n",
    "# and max_df to ignore n-grams that appear in more than 70% documents.\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 2), min_df=15, max_df=0.7)\n",
    "\n",
    "# Use method `fit_transform` to train TfidfVectorizer and return TF-IDF features\n",
    "# from training set\n",
    "X_train_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "\n",
    "# Use method `transform` to return TF-IDF features\n",
    "# from test set\n",
    "X_test_tfidf = tfidf_vec.transform(X_test)\n",
    "\n",
    "# DO NOT MODIFY CODE BELOW\n",
    "print(X_train_tfidf.shape, X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBYg-4Tuy-kl"
   },
   "source": [
    "### 7. Logistic regression model\n",
    "Now we can train a classifier. There are a lot of classification algorithms in ML but its better to start from something simple because simple model can get acceptable results and it will work very fast.\n",
    "\n",
    "In this work we are going to use logistic regression. The model has the following form:\n",
    "\n",
    "$$p(x, θ) = sigmoid(\\sum_{k=1}^{n} θ_kx_k)$$\n",
    "\n",
    "where $n$ is count of features, $x_k$ is value of feature $k$ and $θ_k$ is a weight of feature $k$ and $sigmoid(z) = \\frac{1}{1 + exp(-z)}$.\n",
    "\n",
    "Actually, it is a very simple neural network called perceptron.\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f62fWXnVzOBO"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247349,
     "status": "ok",
     "timestamp": 1729515188091,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "HwV_QR7D5cYf",
    "outputId": "6e67c285-c28d-49d3-a6cb-b37188dc8505",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# We create model with following parameters:\n",
    "# - Cs=10 means that algorithm will use 10 differen regularization \n",
    "#   coefficient and choose the best according to the scoring metric.\n",
    "# - cv=5 means that algorithm will do 5-fold cross validation.\n",
    "# - penalty='l2' means algorithm will use l2 norm for regularization.\n",
    "# - scoring='roc_auc' is a scoring metric that changes from 0 to 1. \n",
    "#   1 means ideal classifier, 0.5 - random classifier. \n",
    "#   We should get something between.\n",
    "\n",
    "model = LogisticRegressionCV(\n",
    "    Cs=10, \n",
    "    cv=5, \n",
    "    penalty='l2', \n",
    "    scoring='roc_auc', \n",
    "    solver='saga', \n",
    "    max_iter=100, \n",
    "    random_state=0, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model on train data and predict probabilities on test set.\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "p_test = model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Look at the first 5 probabilities\n",
    "print(p_test[:5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR6X4GfNrqF1"
   },
   "source": [
    "### 8. Model quality\n",
    "To estimate our model we will look at the ROC-curve and ROC-AUC metric. Recall that ROC-curve reflects the dependence of true positive rate from false positive rate and the more area under the curve the better. What can you say about our model? Is it acceptable? Is it overfitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1729515188632,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "PB2LULcB5cYg",
    "outputId": "50a1ab41-7293-45f1-adaf-e2b39f1b0861"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(model, X_train_tfidf, y_train, ax=ax, label=\"train\")\n",
    "RocCurveDisplay.from_estimator(model, X_test_tfidf, y_test, ax=ax, label=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auZtDex95YyP"
   },
   "source": [
    "### 9. Threshold\n",
    "\n",
    "Now we can choose a threshold for the classifier. Actually it's not very simple task. In this work we will use heuristic.\n",
    "\n",
    "Form two groups from training data. First group should contain data with `target = 0` and second group should contain data with `target = 1`. Then predict probabilities within both groups and look at the distributions of probabilities. What threshold are you going to choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 3454,
     "status": "ok",
     "timestamp": 1729515192084,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "eNE5ehuE3h2g",
    "outputId": "871e9100-983b-4735-a1c9-4ff0bdd6c1a9"
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "# YOUR CODE HERE\n",
    "group_0 = X_train_tfidf[y_train == 0]\n",
    "group_1 = X_train_tfidf[y_train == 1]\n",
    "\n",
    "p_0 = model.predict_proba(group_0)[:, 1]\n",
    "p_1 = model.predict_proba(group_1)[:, 1]\n",
    "\n",
    "group_labels = ['bad', 'good']\n",
    "fig = ff.create_distplot([p_0, p_1], group_labels, bin_size=0.02, show_rug=False)\n",
    "fig.update_layout(\n",
    "    title_text='Distribution of probabilities in ground truth groups', \n",
    "    width=640, height=480, \n",
    "    xaxis_title=\"Probability\", \n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEOubQFAGlWe"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJkDCvnLx6v9"
   },
   "source": [
    "Implement the function `predict` which takes four arguments:\n",
    "\n",
    "* `model` - our classifier\n",
    "* `vectorizer` - any vectrorizer, for example TfidfVectorizer\n",
    "* `texts` - list of input text\n",
    "* `threshold` - threshold\n",
    "\n",
    "and returns classes `0` or `1` for each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoV74Dj75cYg"
   },
   "outputs": [],
   "source": [
    "def predict(model, vectorizer, texts, threshold):\n",
    "    x = [preprocess(t) for t in texts]\n",
    "    x = vectorizer.transform(x)\n",
    "    probs = model.predict_proba(x)[:, 1]\n",
    "    classes = (probs >= threshold).astype(int)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729515192085,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "LZMqV-365cYh",
    "outputId": "c0b6696f-32ba-4e73-972a-2c4c92a95387"
   },
   "outputs": [],
   "source": [
    "# Try it!\n",
    "reviews = [\n",
    "    'This is a disgusting jacket',\n",
    "    'This is an excellent jacket'\n",
    "]\n",
    "\n",
    "classes = predict(model, tfidf_vec, reviews, THRESHOLD) # YOUR CODE HERE\n",
    "\n",
    "for r, c in zip(reviews, classes):\n",
    "    print(f'{r}:', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5CbvKIWGQZg"
   },
   "source": [
    "### 10. Model interpretation\n",
    "\n",
    "Logistic regression is interpreted, which means that we can tell which features (words) in the review affect the rate of the product. The influence of a word is determined by the weight of the model corresponding to it. If the weight is zero, then the word is not affected at all. The higher the value of the weight, the more the corresponding word increases the probability of a positive rate and vice versa.\n",
    "\n",
    "To make a visual interpretation, we can take the top 100 words with the largest positive weights, as well as the top 100 words with the smallest negative weights, and visualize them as word clouds, assuming that weight is the size of a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729515192085,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "Ke3WkqbF5cYg",
    "outputId": "cc195e46-038d-44ef-903f-e6597c456c92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract array of tupels containing word and its weight.\n",
    "\n",
    "word_coefs = [(f, model.coef_[0][i]) for f, i in tfidf_vec.vocabulary_.items()]\n",
    "word_coefs.sort(key=lambda x: x[1])\n",
    "word_coefs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJqSAPWM5cYg"
   },
   "outputs": [],
   "source": [
    "# Top 100 negative words and top 100 positive words\n",
    "\n",
    "word_coefs_negative = {k: abs(v) for k, v in word_coefs[:100]}\n",
    "word_coefs_positive = {k: v for k, v in word_coefs[-100:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPT4-YOp5cYg"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbysstJj5cYg"
   },
   "outputs": [],
   "source": [
    "def draw_word_cloud(word_coefs):\n",
    "    x, y = np.ogrid[:500, :500]\n",
    "    mask = (x - 250) ** 2 + (y - 250) ** 2 > 230 ** 2\n",
    "    mask = 255 * mask.astype(int)\n",
    "\n",
    "    word_cloud = WordCloud(background_color=\"black\", mask=mask)\n",
    "    word_cloud.generate_from_frequencies(word_coefs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(word_cloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1729515192731,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "HYfJRNzW5cYg",
    "outputId": "4ec23275-2ef2-414a-a057-b6116d08b9f2"
   },
   "outputs": [],
   "source": [
    "# Negative rates\n",
    "draw_word_cloud(word_coefs_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1729515193553,
     "user": {
      "displayName": "Andrei Kotseruba",
      "userId": "01711491631127368765"
     },
     "user_tz": -180
    },
    "id": "sciy6NfC5cYg",
    "outputId": "c24ee116-a1fb-4a80-fedd-85bd5d43d229"
   },
   "outputs": [],
   "source": [
    "# Positive rates\n",
    "draw_word_cloud(word_coefs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15f4d6b7130546feb1807f8452d4b8d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30890c0f05d44a0699207d43e95c15b8",
      "placeholder": "​",
      "style": "IPY_MODEL_447ace2b92cd4246a2ba84492f9ccb11",
      "value": "100%"
     }
    },
    "2b9f86fa5775429695296e4b4d686abc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30890c0f05d44a0699207d43e95c15b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37f74dd0fc014c12b8837f0f0ae97bd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd8eb4c615554303a51e87c33ea04617",
      "max": 114160,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e0d4d585bef42c2bd531d33c599d3f0",
      "value": 114160
     }
    },
    "447ace2b92cd4246a2ba84492f9ccb11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e6ed618235e43beb304b2a9821f75ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e77764fedd54b9e8bb391b862491084": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b9f86fa5775429695296e4b4d686abc",
      "placeholder": "​",
      "style": "IPY_MODEL_5f42323de1414ca585f48db27cbdf47a",
      "value": " 114160/114160 [01:16&lt;00:00, 2914.20it/s]"
     }
    },
    "5f42323de1414ca585f48db27cbdf47a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e0d4d585bef42c2bd531d33c599d3f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ffde06366dd438d9d9e725942e6e2bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15f4d6b7130546feb1807f8452d4b8d4",
       "IPY_MODEL_37f74dd0fc014c12b8837f0f0ae97bd6",
       "IPY_MODEL_5e77764fedd54b9e8bb391b862491084"
      ],
      "layout": "IPY_MODEL_5e6ed618235e43beb304b2a9821f75ff"
     }
    },
    "dd8eb4c615554303a51e87c33ea04617": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
