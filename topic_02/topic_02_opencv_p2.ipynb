{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bc1474-af24-435d-9c6e-4f58d3c62bf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ce383-7938-4f81-affc-30a98c0b6926",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 2: Introduction to Computer Vision. Image processing with OpenCV. Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaefe070-4b98-4f25-b7fb-2c623a81bfbd",
   "metadata": {},
   "source": [
    "### 1. Library installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df35b83-6ff6-4710-9103-979ebc5bb5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449d0aa-1ad0-4f82-a082-778cefc58557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a932a-71b4-4d2d-acb6-ecd28df47fd3",
   "metadata": {},
   "source": [
    "### 2. Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a401274-baf0-4804-975f-ef4b3fcf9716",
   "metadata": {},
   "source": [
    "#### 2.1. Read video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823ff04-5594-456c-a8f9-7a0fd90993e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/jovyan/__DATA/DLBA_F25/topic_02'\n",
    "WORK_PATH = '.'\n",
    "IMGS_PATH = 'imgs'\n",
    "VID_NAME = 'Epic_bullet_trace.mp4'\n",
    "OUT_FILE = 'test.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa2ab4-ab2e-4e36-a385-e754a605822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_file = f'{DATA_PATH}/{VID_NAME}'\n",
    "cap = cv2.VideoCapture(vid_file)\n",
    "frames_cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print('video has {} frames and rate {} fps (frames-per-second)'.format(\n",
    "    frames_cnt,\n",
    "    fps\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c5568-432f-4419-a8cf-105bf0ff424a",
   "metadata": {},
   "source": [
    "#### 2.2. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851d895-53d7-4650-947d-a010c64b7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_numbered(i, symbols=5):\n",
    "    \"\"\"\n",
    "    For pretty name of saved video frames.\n",
    "\n",
    "    :i: number of image\n",
    "    :symbols: lenght of saved file name\n",
    "    \n",
    "    \"\"\"\n",
    "    str_num = ''.join([\n",
    "        '0' * (symbols - len(str(i))),\n",
    "        str(i)\n",
    "    ])\n",
    "    return str_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ad02e-805c-4d78-8cbe-933414a058a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_frames(vid_path, start_time, num_frames, save_dir, prefix=''):\n",
    "    \"\"\"\n",
    "    Function takes the path to video\n",
    "    and saves few frames to the disk.\n",
    "\n",
    "    :vid_path: path to video file\n",
    "    :start_time: where to start capturing frames\n",
    "    :num_frames: ho many frames to save\n",
    "    :save_dir: path to save to\n",
    "\n",
    "    \"\"\"\n",
    "    files_names = []\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    frames_cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    start_pos = int(start_time * fps)\n",
    "    end_pos = int(start_pos + num_frames) if num_frames else int(frames_cnt)\n",
    "    if end_pos <= frames_cnt:\n",
    "        for frame_num in tqdm(range(start_pos, end_pos)):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            res, frame = cap.read()\n",
    "            if res:\n",
    "                file_name = '{}/{}_{}.png'.format(\n",
    "                    save_dir, \n",
    "                    prefix,\n",
    "                    str_numbered(frame_num)\n",
    "                )\n",
    "                cv2.imwrite(file_name, frame)\n",
    "                files_names.append(file_name)\n",
    "    else:\n",
    "        print('out of video lenght')\n",
    "    c3, c4, c5 = int(cap.get(3)), int(cap.get(4)), cap.get(5)\n",
    "    cap.release()\n",
    "    return files_names, frames_cnt, c3, c4, c5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffd59f6-b576-4041-ab52-0c410ebecd08",
   "metadata": {},
   "source": [
    "#### 2.3. Save video to frame images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe3cf1-71de-49ea-ade8-8de7d1043ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = f'{WORK_PATH}/{IMGS_PATH}'\n",
    "os.makedirs(imgs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f49826-8627-4921-9611-5237cc23a0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_names, frames_cnt, c3, c4, c5 = get_frames(\n",
    "    vid_path=vid_file,\n",
    "    start_time=0, \n",
    "    num_frames=None, \n",
    "    save_dir=imgs_dir, \n",
    "    prefix='frame'\n",
    ")\n",
    "len(files_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb344ed-8b32-4314-aa75-3be99248dc02",
   "metadata": {},
   "source": [
    "### 3. Finding trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa880ad-607d-42fc-8d54-97511b9855d4",
   "metadata": {},
   "source": [
    "About the [phenomenon of Vapor trail and Bullet trace](https://snipercountry.com/bullet-trail/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fba845-9d15-4854-90e9-0bf2f07161c4",
   "metadata": {},
   "source": [
    "#### 3.1. Use OpenCV basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b6d29-9fc7-437c-85ba-20c95c44407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(file_path, canny=True):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    assert img is not None, 'file could not be read, check if file exists'\n",
    "    if canny:\n",
    "        return cv2.Canny(img, 100, 200, 3)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "\n",
    "def img_mean(files_names, frame_num, cover_l, cover_r, canny=False):\n",
    "    files_l = files_names[max(0, frame_num - cover_l):frame_num]\n",
    "    files_r = files_names[frame_num + 1:min(len(files_names), frame_num + cover_r + 1)]\n",
    "    files_l.extend(files_r)\n",
    "    frames = []\n",
    "    for file_name in files_l:\n",
    "        frames.append(get_img(file_name, canny=canny))\n",
    "    mean_frame = np.mean(frames, axis=0).astype(dtype=np.uint8)\n",
    "    return mean_frame\n",
    "\n",
    "\n",
    "def img_diff(img1, img2, mask, psize=.1, quantile=.95):\n",
    "    img = cv2.absdiff(\n",
    "        cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY), \n",
    "        cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    )\n",
    "    size = int(psize * np.mean(img.shape))\n",
    "    kernel = np.ones((size, size), np.float32) / (size * size)\n",
    "    mask = cv2.filter2D(mask, -1, kernel)\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "    img = cv2.bitwise_and(img, mask)\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    th, img = cv2.threshold(\n",
    "        img, \n",
    "        np.quantile(img, quantile), \n",
    "        np.max(img), \n",
    "        cv2.THRESH_BINARY\n",
    "    )\n",
    "    return img2, img\n",
    "\n",
    "\n",
    "def img_contours(img, psize=.1):\n",
    "    size = int(psize * np.mean(img.shape))\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        image=img, \n",
    "        mode=cv2.RETR_TREE, \n",
    "        method=cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    bboxes = []\n",
    "    for c in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        if w * h > size * size:\n",
    "            bboxes.append([x, y, x + w, y + h])\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def draw_bboxes(img, boxes):\n",
    "    for bbox in boxes:\n",
    "        cv2.rectangle(\n",
    "            img, \n",
    "            bbox[:2], \n",
    "            bbox[2:], \n",
    "            (255, 0, 0), \n",
    "            2\n",
    "        )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5681c7-f8d9-414b-b66e-99db61829e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_bboxes(fnum, gap_l, gap_r, pkersize, psize, quantile):\n",
    "    img1 = img_mean(\n",
    "        files_names, \n",
    "        frame_num=fnum, \n",
    "        cover_l=gap_l, \n",
    "        cover_r=gap_r, \n",
    "        canny=False\n",
    "    )\n",
    "    img2 = get_img(\n",
    "        file_path=f'{imgs_dir}/frame_{str_numbered(fnum)}.png', \n",
    "        canny=False\n",
    "    )\n",
    "    mask = get_img(\n",
    "        file_path=f'{imgs_dir}/frame_{str_numbered(fnum)}.png', \n",
    "        canny=True\n",
    "    )\n",
    "    img_orig, img = img_diff(\n",
    "        img1, img2, mask,\n",
    "        psize=pkersize,\n",
    "        quantile=quantile\n",
    "    )\n",
    "    bboxes = img_contours(img, psize=psize)\n",
    "    return img_orig, img, bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b370d0b-62f9-41ff-ba6c-309bc889cf22",
   "metadata": {},
   "source": [
    "#### 3.2. Test for one frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b4dd7-4069-4e52-935b-397c4c93fa81",
   "metadata": {},
   "source": [
    "Result highly varies depending on the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdda406-b8b2-4ab4-9d8c-6b543190eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAP_L = 10\n",
    "GAP_R = 10\n",
    "PKERSIZE = .1\n",
    "PSIZE = .1\n",
    "QUANTILE = .95\n",
    "FNUM = 20\n",
    "\n",
    "img_orig, img, bboxes = img_bboxes(\n",
    "    fnum=FNUM, \n",
    "    gap_l=GAP_L, \n",
    "    gap_r=GAP_R, \n",
    "    pkersize=PKERSIZE, \n",
    "    psize=PSIZE, \n",
    "    quantile=QUANTILE\n",
    ")\n",
    "img_orig = draw_bboxes(img_orig, bboxes)\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(img_orig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacd705-944b-428a-a3fe-3f39629d1ef3",
   "metadata": {},
   "source": [
    "#### 3.3. Process many frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef738a57-e6c3-491a-9305-53d0f1aeeeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bboxes = []\n",
    "for frame_num in tqdm(range(15, 35)):\n",
    "    img_orig, img, bboxes = img_bboxes(\n",
    "        fnum=frame_num, \n",
    "        gap_l=GAP_L, \n",
    "        gap_r=GAP_R, \n",
    "        pkersize=PKERSIZE, \n",
    "        psize=PSIZE, \n",
    "        quantile=QUANTILE\n",
    "    )\n",
    "    all_bboxes.append(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960584a-d5ba-41aa-8f1d-532a07c261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bboxes in all_bboxes:\n",
    "    img_orig = draw_bboxes(img_orig, bboxes)\n",
    "plt.imshow(img_orig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb21b43-e5b2-4b21-b418-7214c626d9a3",
   "metadata": {},
   "source": [
    "### 4. Write results to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56655ec6-ef5f-419a-8dde-9b7b157f8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter(\n",
    "    f'{WORK_PATH}/{OUT_FILE}',\n",
    "    cv2.VideoWriter_fourcc(*'XVID'), \n",
    "    c5,\n",
    "    (int(c3), int(c4)),\n",
    "    True\n",
    ")\n",
    "trace = []\n",
    "for i, frame_num in enumerate(tqdm(range(15, 35))):\n",
    "    file_path = f'{imgs_dir}/frame_{str_numbered(frame_num)}.png'\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = draw_bboxes(img, all_bboxes[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    out.write(img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac67848-e26c-4cae-9977-9725ee27e130",
   "metadata": {},
   "source": [
    "### 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e6a02-4380-4584-8058-48c8f118fdc1",
   "metadata": {},
   "source": [
    "#### + Pros +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440ede6-0b7d-4517-8bb6-246340cf5acb",
   "metadata": {},
   "source": [
    "1. Easy to implement, basic math functions only\n",
    "2. Fast computations, can run e.g. on Rasberry PI or other lightweight devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fbeda7-5be8-405c-96cd-31d6777e74e3",
   "metadata": {},
   "source": [
    "#### - Cons -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f987e-a23a-4440-86ba-93f46e5cded4",
   "metadata": {},
   "source": [
    "1. Highly depends on hyperparameters and should be tuned for every video\n",
    "2. Can generate many false positives\n",
    "3. Generally not works..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3f617-0822-4ba1-9d49-f43531da6a97",
   "metadata": {},
   "source": [
    "Should we try neural networks instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ba536-9c36-4508-8e22-759c805fc819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
